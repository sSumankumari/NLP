{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFT4zbqFwRmr"
   },
   "source": [
    "### **Bag of n_grams: Exercise**\n",
    "\n",
    "- Fake news refers to misinformation or disinformation in the country which is spread through word of mouth and more recently through digital communication such as What's app messages, social media posts, etc.\n",
    "\n",
    "- Fake news spreads faster than Real news and creates problems and fear among groups and in society.\n",
    "\n",
    "- We are going to address these problems using classical NLP techniques and going to classify whether a given message/ text is **Real or Fake Message**.\n",
    "\n",
    "- You will use a Bag of n-grams to pre-process the text and apply different classification algorithms.\n",
    "\n",
    "- Sklearn CountVectorizer has the inbuilt implementations for Bag of Words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBcs8GQb0C9_"
   },
   "source": [
    "### **About Data: Fake News Detection**\n",
    "\n",
    "Credits: https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset\n",
    "\n",
    "\n",
    "- This data consists of two columns.\n",
    "        - Text\n",
    "        - label\n",
    "- Text is the statements or messages regarding a particular event/situation.\n",
    "\n",
    "- label feature tells whether the given Text is Fake or Real.\n",
    "\n",
    "- As there are only 2 classes, this problem comes under the **Binary Classification.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "KiYilX-lv_Vm",
    "outputId": "3a7bcc05-8e94-4d3d-c2a7-89d74f2b8202"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9900, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top Trump Surrogate BRUTALLY Stabs Him In The...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. conservative leader optimistic of common ...</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump proposes U.S. tax overhaul, stirs concer...</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Court Forces Ohio To Allow Millions Of Illega...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democrats say Trump agrees to work on immigrat...</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text label\n",
       "0   Top Trump Surrogate BRUTALLY Stabs Him In The...  Fake\n",
       "1  U.S. conservative leader optimistic of common ...  Real\n",
       "2  Trump proposes U.S. tax overhaul, stirs concer...  Real\n",
       "3   Court Forces Ohio To Allow Millions Of Illega...  Fake\n",
       "4  Democrats say Trump agrees to work on immigrat...  Real"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Fake_Real_Data.csv')\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N59dp0n1v_XU",
    "outputId": "3a438088-ff3f-4f57-9fbf-565b96693f02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fake    5000\n",
       "Real    4900\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Zr-vBY7xv_a3",
    "outputId": "1c447daa-237a-48c0-9b3f-3342f63093e2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top Trump Surrogate BRUTALLY Stabs Him In The...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. conservative leader optimistic of common ...</td>\n",
       "      <td>Real</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump proposes U.S. tax overhaul, stirs concer...</td>\n",
       "      <td>Real</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Court Forces Ohio To Allow Millions Of Illega...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democrats say Trump agrees to work on immigrat...</td>\n",
       "      <td>Real</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text label  label_num\n",
       "0   Top Trump Surrogate BRUTALLY Stabs Him In The...  Fake          0\n",
       "1  U.S. conservative leader optimistic of common ...  Real          1\n",
       "2  Trump proposes U.S. tax overhaul, stirs concer...  Real          1\n",
       "3   Court Forces Ohio To Allow Millions Of Illega...  Fake          0\n",
       "4  Democrats say Trump agrees to work on immigrat...  Real          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add the new column \"label_num\" which gives a unique number to each of these labels \n",
    "df['label_num'] = df['label'].map({'Fake':0, 'Real':1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ev3bWDnA3tM-"
   },
   "source": [
    "### **Modelling without Pre-processing Text data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hs94POE23Zjd"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df.Text,\n",
    "    df.label_num,\n",
    "    test_size=0.2,\n",
    "    random_state=2024,\n",
    "    stratify=df.label_num\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4I4S1PJG3ZlO",
    "outputId": "0d9865bd-48b9-4def-cfed-c740d6e02f8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7920,) (1980,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7920,) (1980,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2sO9uck4ILs"
   },
   "source": [
    "**Attempt 1** :\n",
    "\n",
    "1. using sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "\n",
    "**Note:**\n",
    "- using CountVectorizer with unigram, bigram, and trigrams.\n",
    "- use KNN as the classifier with n_neighbors of 10 and metric as 'euclidean' distance.\n",
    "- print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LLs6pmXE3Zou",
    "outputId": "1bbb4bf1-0b1e-4c5e-f751-fa4b331e772f"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LLs6pmXE3Zou",
    "outputId": "1bbb4bf1-0b1e-4c5e-f751-fa4b331e772f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Kneighbors Classifier with metric 'euclidean' distance! \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.49      0.65      1000\n",
      "           1       0.65      0.98      0.78       980\n",
      "\n",
      "    accuracy                           0.73      1980\n",
      "   macro avg       0.80      0.73      0.71      1980\n",
      "weighted avg       0.80      0.73      0.71      1980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf1 = Pipeline([\n",
    "    ('vectorizer_trigrams', CountVectorizer(ngram_range=(1,3))),\n",
    "    ('KNN', (KNeighborsClassifier(n_neighbors=10, metric='euclidean')))\n",
    "])\n",
    "\n",
    "clf1.fit(x_train, y_train)\n",
    "\n",
    "y_pred1 = clf1.predict(x_test)\n",
    "\n",
    "print(\"Using Kneighbors Classifier with metric 'euclidean' distance! \\n\")\n",
    "print(classification_report(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OU0g90Ra7BTW"
   },
   "source": [
    "**Attempt 2** :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "\n",
    "**Note:**\n",
    "- using CountVectorizer with unigram, bigram, and trigrams.\n",
    "- use **KNN** as the classifier with n_neighbors of 10 and metric as 'cosine' distance.\n",
    "- print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eEsLSrIC3Zqf",
    "outputId": "b0354edc-1d3f-401b-c1ed-dd0cb7b769b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Kneighbors Classifier with metric 'cosine' distance! \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.52      0.68      1000\n",
      "           1       0.67      1.00      0.80       980\n",
      "\n",
      "    accuracy                           0.76      1980\n",
      "   macro avg       0.83      0.76      0.74      1980\n",
      "weighted avg       0.83      0.76      0.74      1980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf2 = Pipeline([\n",
    "    ('vectorizer_trigrams', CountVectorizer(ngram_range=(1,3))),\n",
    "    ('KNN', (KNeighborsClassifier(n_neighbors=10, metric='cosine')))\n",
    "])\n",
    "\n",
    "clf2.fit(x_train, y_train)\n",
    "\n",
    "y_pred2 = clf2.predict(x_test)\n",
    "\n",
    "print(\"Using Kneighbors Classifier with metric 'cosine' distance! \\n\")\n",
    "print(classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kl5zoCbE8jds"
   },
   "source": [
    "\n",
    "**Attempt 3** :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "\n",
    "**Note:**\n",
    "- using CountVectorizer with only trigrams.\n",
    "- use **RandomForest** as the classifier.\n",
    "- print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4bywjvZyv_ga",
    "outputId": "e2c93b51-8508-4c5a-b0ca-54e34ebe5075"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Random Forest Classifier! \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      1000\n",
      "           1       0.99      1.00      0.99       980\n",
      "\n",
      "    accuracy                           0.99      1980\n",
      "   macro avg       0.99      0.99      0.99      1980\n",
      "weighted avg       0.99      0.99      0.99      1980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf3 = Pipeline([\n",
    "    ('vectorizer_n_grams', CountVectorizer(ngram_range=(3,3))),\n",
    "    ('random_forest', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "clf3.fit(x_train, y_train)\n",
    "\n",
    "y_pred3 = clf3.predict(x_test)\n",
    "\n",
    "print(\"Using Random Forest Classifier! \\n\")\n",
    "print(classification_report(y_test, y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMeeE5zB8tZz"
   },
   "source": [
    "\n",
    "**Attempt 4** :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "\n",
    "**Note:**\n",
    "- using CountVectorizer with both unigram and bigrams.\n",
    "- use **Multinomial Naive Bayes** as the classifier with an alpha value of 0.75.\n",
    "- print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9cP_zluNwBjS",
    "outputId": "108dd86a-5938-4040-9813-00b82d393ad1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Multinomial Naive Bayes! \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      1000\n",
      "           1       0.98      0.99      0.99       980\n",
      "\n",
      "    accuracy                           0.99      1980\n",
      "   macro avg       0.99      0.99      0.99      1980\n",
      "weighted avg       0.99      0.99      0.99      1980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf4 = Pipeline([\n",
    "    ('vectorizer_bigrams', CountVectorizer(ngram_range = (1,2))),\n",
    "    ('multinomial_nb', MultinomialNB(alpha = 0.75))\n",
    "])\n",
    "\n",
    "clf4.fit(x_train, y_train)\n",
    "\n",
    "y_pred4 = clf4.predict(x_test)\n",
    "\n",
    "print(\"Using Multinomial Naive Bayes! \\n\")\n",
    "print(classification_report(y_test, y_pred4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IoFBbMga9tPB"
   },
   "source": [
    "<h3>Use text pre-processing to remove stop words, punctuations and apply lemmatization </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "R14_wUhGjqj5"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "    \n",
    "    return \" \".join(filtered_tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JIKvTbl9jql0"
   },
   "outputs": [],
   "source": [
    "df['preprocessed_txt'] = df['Text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "0O-uZncOjqpG",
    "outputId": "02d45596-aa7a-449d-dbba-3afd2bd8908b"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMVuYaYM-giF"
   },
   "source": [
    "**Build a model with pre processed text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D25BcI45jqrE"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.preprocessed_txt, \n",
    "    df.label_num,\n",
    "    test_size=0.2,\n",
    "    random_state=2022,\n",
    "    stratify=df.label_num\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOh36PXR-nR_"
   },
   "source": [
    "**Let's check the scores with our best model till now**\n",
    "- Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbfpQ5-kDgMt"
   },
   "source": [
    "**Attempt1** :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "\n",
    "**Note:**\n",
    "- using CountVectorizer with only trigrams.\n",
    "- use **RandomForest** as the classifier.\n",
    "- print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BGQusE2rjquN",
    "outputId": "d1b83f99-0983-4feb-e24e-e3f9f2e09632"
   },
   "outputs": [],
   "source": [
    "clf5 = Pipeline([\n",
    "    ('vectorizer_n_grams', CountVectorizer(ngram_range=(3,3))),\n",
    "    ('random_forest', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "clf5.fit(x_train, y_train)\n",
    "\n",
    "y_pred5 = clf5.predict(x_test)\n",
    "\n",
    "print(\"Using Random Forest Classifier! \\n\")\n",
    "print(classification_report(y_test, y_pred5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GB78pcAPEFQZ"
   },
   "source": [
    "**Attempt2** :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "\n",
    "**Note:**\n",
    "- using CountVectorizer with unigram, Bigram, and trigrams.\n",
    "- use **RandomForest** as the classifier.\n",
    "- print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rpwvD1mvjqvx",
    "outputId": "bbee2e0b-98da-4ae0-a480-259e0de8fa29"
   },
   "outputs": [],
   "source": [
    "clf6 = Pipeline([\n",
    "    ('vectorizer_n_grams', CountVectorizer(ngram_range=(1,3))),\n",
    "    ('random_forest', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "clf6.fit(x_train, y_train)\n",
    "\n",
    "y_pred6 = clf6.predict(x_test)\n",
    "\n",
    "print(\"Using Random Forest Classifier! \\n\")\n",
    "print(classification_report(y_test, y_pred6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "id": "SLT0vKGRHAMF",
    "outputId": "540746d1-2dec-4585-918b-c4afba111e26"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred6)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "bag_of_n_grams_exercise.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
